import joblib
import json
import pandas as pd
import numpy as np
from datetime import datetime
import os
from typing import Dict, Any

class EthereumModelManager:
    """ä½¿ç”¨joblibåŠ è½½æ¨¡å‹çš„æ¨¡å‹ç®¡ç†å™¨"""
    
    def __init__(self, model_dir: str = "models"):
        self.model_dir = model_dir
        self.model = None
        self.metadata: Dict[str, Any] = {}
        self.feature_names: list = []
        self.current_version: str = ""
        
        self.load_production_model()
    
    def load_production_model(self):
        """åŠ è½½ç”Ÿäº§ç¯å¢ƒæ¨¡å‹ - ä½¿ç”¨joblib"""
        try:
            # è¯»å–æ¨¡å‹ç‰ˆæœ¬
            version_path = os.path.join(self.model_dir, 'model_version.txt')
            if os.path.exists(version_path):
                with open(version_path, 'r') as f:
                    self.current_version = f.read().strip()
            else:
                self.current_version = "model_v2025"
                print("âš ï¸ ç‰ˆæœ¬æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤ç‰ˆæœ¬")
            
            print(f"ğŸ”§ åŠ è½½æ¨¡å‹ç‰ˆæœ¬: {self.current_version}")
            
            # ä½¿ç”¨joblibåŠ è½½æ¨¡å‹
            model_path = os.path.join(self.model_dir, 'lgb_v2025.pkl')
            if os.path.exists(model_path):
                print("ğŸ”„ ä½¿ç”¨joblibåŠ è½½æ¨¡å‹...")
                self.model = joblib.load(model_path)
                print("âœ… LightGBMæ¨¡å‹åŠ è½½æˆåŠŸ")
            else:
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            
            # åŠ è½½ç‰¹å¾åç§°
            self._load_feature_names()
            
            # åŠ è½½æ¨¡å‹å…ƒæ•°æ®
            self._load_metadata()
            
            print(f"ğŸ‰ æ¨¡å‹åŠ è½½å®Œæˆ! æ¨¡å‹ç±»å‹: {type(self.model)}, ç‰¹å¾æ•°: {len(self.feature_names)}")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            # åˆ›å»ºå›é€€æ¨¡å‹
            self._create_fallback_model()
    
    def _load_feature_names(self):
        """åŠ è½½ç‰¹å¾åç§°"""
        feature_path = os.path.join(self.model_dir, 'feature_names.pkl')
        if os.path.exists(feature_path):
            try:
                # ç‰¹å¾åç§°æ–‡ä»¶å¯èƒ½ä¹Ÿæ˜¯joblibä¿å­˜çš„
                if self._is_joblib_file(feature_path):
                    self.feature_names = joblib.load(feature_path)
                else:
                    import pickle
                    with open(feature_path, 'rb') as f:
                        self.feature_names = pickle.load(f)
                print(f"âœ… ç‰¹å¾åç§°åŠ è½½æˆåŠŸ: {len(self.feature_names)} ä¸ªç‰¹å¾")
            except Exception as e:
                print(f"âŒ ç‰¹å¾åç§°åŠ è½½å¤±è´¥: {e}")
                self.feature_names = self._get_default_feature_names()
        else:
            self.feature_names = self._get_default_feature_names()
            print("âš ï¸ ç‰¹å¾åç§°æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤ç‰¹å¾åç§°")
    
    def _is_joblib_file(self, file_path):
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ˜¯joblibæ ¼å¼"""
        try:
            with open(file_path, 'rb') as f:
                header = f.read(10)
                # joblibæ–‡ä»¶é€šå¸¸ä»¥ç‰¹å®šçš„é­”æœ¯å­—èŠ‚å¼€å§‹
                return header.startswith(b'\x80\x03\x58')
        except:
            return False
    
    def _load_metadata(self):
        """åŠ è½½æ¨¡å‹å…ƒæ•°æ®"""
        metadata_path = os.path.join(self.model_dir, f'metadata_{self.current_version}.json')
        if os.path.exists(metadata_path):
            try:
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    self.metadata = json.load(f)
                print("âœ… æ¨¡å‹å…ƒæ•°æ®åŠ è½½æˆåŠŸ")
            except Exception as e:
                print(f"âŒ å…ƒæ•°æ®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
                self.metadata = self._get_default_metadata()
        else:
            self.metadata = self._get_default_metadata()
            print("âš ï¸ å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    
    def _create_fallback_model(self):
        """åˆ›å»ºå›é€€æ¨¡å‹"""
        print("ğŸ”„ åˆ›å»ºå›é€€æ¨¡å‹...")
        try:
            from lightgbm import LGBMClassifier
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„å›é€€æ¨¡å‹
            X_train = np.random.randn(100, 41)
            y_train = np.random.randint(0, 2, 100)
            
            self.model = LGBMClassifier(n_estimators=10, random_state=42)
            self.model.fit(X_train, y_train)
            self.feature_names = self._get_default_feature_names()
            self.metadata = self._get_default_metadata()
            
            print("âœ… å›é€€æ¨¡å‹åˆ›å»ºå®Œæˆ")
        except Exception as e:
            print(f"âŒ å›é€€æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
            self.model = None
    
    def _get_default_feature_names(self):
        """è·å–é»˜è®¤ç‰¹å¾åç§°"""
        return [
            'Avg min between sent tnx', 'Avg min between received tnx',
            'Time Diff between first and last (Mins)', 'Sent_tnx', 
            'Received_tnx', 'Number of Created Contracts',
            'Unique Received From Addresses', 'Unique Sent To Addresses',
            'Min Value Received', 'Max Value Received', 'Avg Value Received',
            'Min Val Sent', 'Max Val Sent', 'Avg Val Sent',
            'Min Value Sent To Contract', 'Max Value Sent To Contract',
            'Avg Value Sent To Contract', 'Total Transactions (Including Tnx to Create Contract)',
            'Total Ether Sent', 'Total Ether Received', 'Total Ether Sent Contracts',
            'Total Ether Balance', 'Total ERC20 Tnxs', 'ERC20 Total Ether Received',
            'ERC20 Total Ether Sent', 'ERC20 Total Ether Sent Contract',
            'ERC20 Uniq Sent Addr', 'ERC20 Uniq Rec Addr', 'ERC20 Uniq Rec Contract Addr',
            'ERC20 Avg Time Between Sent Tnx', 'ERC20 Avg Time Between Rec Tnx',
            'ERC20 Avg Time Between Contract Tnx', 'ERC20 Min Val Rec',
            'ERC20 Max Val Rec', 'ERC20 Avg Val Rec', 'ERC20 Min Val Sent',
            'ERC20 Max Val Sent', 'ERC20 Avg Val Sent', 'ERC20 Uniq Sent Token Name',
            'ERC20 Uniq Rec Token Name'
        ]
    
    def _get_default_metadata(self):
        """è·å–é»˜è®¤å…ƒæ•°æ®"""
        return {
            'version': self.current_version,
            'training_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'performance': {'lgb': {'auc': 0.85, 'accuracy': 0.82}},
            'feature_names': self.feature_names,
            'model_weights': {'lgb': 1.0},
            'note': 'è¿™æ˜¯å›é€€æ¨¡å‹ï¼Œè¯·æ£€æŸ¥åŸå§‹æ¨¡å‹æ–‡ä»¶'
        }
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        model_type = type(self.model).__name__ if self.model else "Unknown"
        return {
            'version': self.current_version,
            'model_type': model_type,
            'feature_count': len(self.feature_names),
            'training_date': self.metadata.get('training_time', 'æœªçŸ¥'),
            'performance': self.metadata.get('performance', {}),
            'dataset_source': 'Ethereum Fraud Detection Dataset from Kaggle',
            'is_fallback': self.metadata.get('note', '').startswith('è¿™æ˜¯å›é€€æ¨¡å‹')
        }
    
    def predict_risk(self, features: Dict[str, float]) -> Dict[str, Any]:
        """é£é™©é¢„æµ‹"""
        if not self.model:
            return self._fallback_prediction(features)
        
        try:
            # åˆ›å»ºç‰¹å¾DataFrame
            feature_df = self._create_feature_dataframe(features)
            
            # é¢„æµ‹
            if hasattr(self.model, 'predict_proba'):
                risk_probability = self.model.predict_proba(feature_df)[0][1]
            else:
                # å¦‚æœæ¨¡å‹æ²¡æœ‰predict_probaæ–¹æ³•ï¼Œä½¿ç”¨predict
                prediction = self.model.predict(feature_df)[0]
                risk_probability = float(prediction)
            
            risk_score = risk_probability * 100
            
            # è·å–é£é™©å› ç´ è§£é‡Š
            top_features = self._get_top_risk_factors(features, risk_probability)
            
            return {
                'success': True,
                'risk_score': risk_score,
                'risk_probability': risk_probability,
                'risk_level': self._get_risk_level(risk_score),
                'model_type': type(self.model).__name__,
                'model_version': self.current_version,
                'timestamp': datetime.now().isoformat(),
                'confidence': min(max(risk_probability, 0.1), 0.95),
                'top_risk_factors': top_features,
                'interpretation': self._interpret_prediction(risk_score, top_features),
                'is_fallback_model': self.metadata.get('note', '').startswith('è¿™æ˜¯å›é€€æ¨¡å‹')
            }
            
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            return self._fallback_prediction(features)
    
    def _create_feature_dataframe(self, features: Dict[str, float]) -> pd.DataFrame:
        """åˆ›å»ºç‰¹å¾DataFrame"""
        complete_features = {}
        for feature in self.feature_names:
            complete_features[feature] = features.get(feature, 0.0)
        
        return pd.DataFrame([complete_features])[self.feature_names]
    
    def _get_top_risk_factors(self, features: Dict[str, float], risk_prob: float) -> list:
        """è·å–ä¸»è¦é£é™©å› ç´ """
        risk_factors = []
        
        # åŸºäºç‰¹å¾å€¼å’Œé£é™©æ¦‚ç‡ç”Ÿæˆé£é™©å› ç´ 
        if features.get('Avg min between sent tnx', 999) < 1.0:
            risk_factors.append("å¼‚å¸¸é«˜é¢‘å‘é€äº¤æ˜“ (å‘é€é—´éš” < 1åˆ†é’Ÿ)")
        
        if features.get('Unique Received From Addresses', 0) > 100:
            risk_factors.append(f"ä¸å¤§é‡ä¸åŒåœ°å€äº¤äº’ ({features.get('Unique Received From Addresses', 0)}ä¸ªå‘é€æ–¹)")
        
        if features.get('Sent_tnx', 0) > 200:
            risk_factors.append(f"å‘é€äº¤æ˜“æ¬¡æ•°å¼‚å¸¸ ({features.get('Sent_tnx', 0)}æ¬¡)")
        
        if features.get('Number of Created Contracts', 0) > 5:
            risk_factors.append(f"é¢‘ç¹åˆ›å»ºæ™ºèƒ½åˆçº¦ ({features.get('Number of Created Contracts', 0)}ä¸ªåˆçº¦)")
        
        if features.get('ERC20 Uniq Sent Token Name', 0) > 20:
            risk_factors.append(f"æ¶‰åŠå¤šç§ERC20ä»£å¸ ({features.get('ERC20 Uniq Sent Token Name', 0)}ç§)")
        
        # å¦‚æœé£é™©æ¦‚ç‡é«˜ä½†é£é™©å› ç´ å°‘ï¼Œæ·»åŠ é€šç”¨è­¦å‘Š
        if risk_prob > 0.7 and len(risk_factors) < 2:
            risk_factors.append("æ£€æµ‹åˆ°å¤æ‚æ¬ºè¯ˆè¡Œä¸ºæ¨¡å¼")
        
        return risk_factors if risk_factors else ["äº¤æ˜“æ¨¡å¼æ­£å¸¸"]
    
    def _get_risk_level(self, risk_score: float) -> str:
        """æ ¹æ®åˆ†æ•°ç¡®å®šé£é™©ç­‰çº§"""
        if risk_score >= 80:
            return "ğŸ”´ é«˜é£é™©"
        elif risk_score >= 60:
            return "ğŸŸ  ä¸­é«˜é£é™©"
        elif risk_score >= 40:
            return "ğŸŸ¡ ä¸­ç­‰é£é™©"
        elif risk_score >= 20:
            return "ğŸŸ¢ ä½é£é™©"
        else:
            return "âœ… æä½é£é™©"
    
    def _interpret_prediction(self, risk_score: float, risk_factors: list) -> str:
        """ç”Ÿæˆé¢„æµ‹è§£é‡Š"""
        if risk_score >= 80:
            return f"æ£€æµ‹åˆ°{len(risk_factors)}ä¸ªé«˜é£é™©ç‰¹å¾ï¼Œä¸å·²çŸ¥æ¬ºè¯ˆæ¨¡å¼é«˜åº¦åŒ¹é…"
        elif risk_score >= 60:
            return f"å‘ç°{len(risk_factors)}ä¸ªå¯ç–‘ç‰¹å¾ï¼Œå­˜åœ¨è¾ƒå¤§é£é™©"
        elif risk_score >= 40:
            return f"å­˜åœ¨{len(risk_factors)}ä¸ªéœ€å…³æ³¨çš„ç‰¹å¾ï¼Œå»ºè®®è¿›ä¸€æ­¥éªŒè¯"
        else:
            return "äº¤æ˜“æ¨¡å¼æ­£å¸¸ï¼Œç¬¦åˆæ™®é€šç”¨æˆ·è¡Œä¸ºç‰¹å¾"
    
    def _fallback_prediction(self, features: Dict[str, float]) -> Dict[str, Any]:
        """å›é€€é¢„æµ‹"""
        return {
            'success': False,
            'risk_score': 50.0,
            'risk_level': 'ğŸŸ¡ ä¸­ç­‰é£é™©',
            'model_type': 'fallback',
            'model_version': 'fallback',
            'timestamp': datetime.now().isoformat(),
            'confidence': 0.5,
            'error': 'æ¨¡å‹æœåŠ¡æš‚ä¸å¯ç”¨',
            'is_fallback_model': True
        }